{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62cd9b05",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3D Morphable Model Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c0aae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 0. importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8511d519",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from summer2022_toolbox.visualization_3D_objects import *\n",
    "from summer2022_toolbox.preprocessing import *\n",
    "from summer2022_toolbox.read_object import *\n",
    "from summer2022_toolbox.model_averaging import *\n",
    "from summer2022_toolbox.model_PCA import *\n",
    "from summer2022_toolbox.morphable_model import *\n",
    "from summer2022_toolbox.model_evaluation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05ce56f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "        The dataset we are using in this tutorial is ModelNet40: Princeton's free 3D Object dataset that contains CAD models from 40 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b14778f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. Introduction to 3D Morphable Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c30f4ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The cornerstone of 3D Morphable Models were first proposed by Blanz and Vetter in 1999. It represents a 3D model with a linear combination of examplar shapes. According to Blanz and Vetter's work, there are three types of variations for facial 3DMMs: A shape model that captures geometric variations, an expression model that captures facial expressions, and an appearance model that captures variations in textures and illuminations. In this tutorial, we will only focus on the most basic shape model, which is a global shape model proposed in the same work of Blanz and Vetter, to help readers to capture the basic ideas of 3D Morphable Models. \n",
    "\n",
    "Morphable model requries full correspondence within the dataset. It means that each component in one shape represent the position of the same point in all shapes. Achieveing this full correspondence is the main challenge in building a morphable model. In the dataset we are using (ModelNet40), each 3D shape has different size, orientation, and number of points. Thus, our first step will discuss how do we unify those features. But we will leave the unifying of number of points and achieving full correspondence in Step 2, as it can be achieved when calculating the average shape. \n",
    "\n",
    "Now we have full correspondence within the dataset, we can describe any new shape $S_{model}$ as a linear combination of the m examplar shapes $S$:  \n",
    "\n",
    "$$\n",
    "S_{model} = \\sum_{i=1}^{m}a_{i}S_{i}\n",
    "$$\n",
    "\n",
    "This algorithm can be optimized by representing the unique parts of each examplar shape $S_{i}$ as a sum of an average model $\\overline{S}$ and a linear combination of eigenvectors $s_{i}$: \n",
    "\n",
    "$$\n",
    "S_{i} = \\overline{S} + \\alpha_{i}s_{i}\n",
    "$$\n",
    "\n",
    "We can pick the first k dominating eigenvectors use Principle Component Analysis (PCA). Once we finished calculating the average model and the eigenvectors, we have the morphable model to describe or create any new shape $S_{model}$ with a linear function:\n",
    "\n",
    "$$\n",
    "S_{model} = \\overline{S} + \\sum_{i=1}^{m - 1}\\alpha_{i}s_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a2876",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ce3c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Scale and Downsampling data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483584dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, we need to unify the size of all 3D shapes to a target size. We also need to downsample the shape to reduce our cost of calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b183bcea",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#test\n",
    "filename = \"ModelNet40/car/train/car_0001.off\"\n",
    "source = read_pointcloud(filename)\n",
    "#scale to a target size, downsample with specified voxel size\n",
    "source_down, source_fpfh = prepare_point_cloud(source, target_size=1000, voxel_size=20)\n",
    "source_points = np.asarray(source.points).T #(3, n_points) data\n",
    "source_down_points = np.asarray(source_down.points).T\n",
    "\n",
    "print(\"Original number of points: \", source_points.shape[1])\n",
    "print(\"Number of points after downsampling: \", source_down_points.shape[1])\n",
    "\n",
    "'''\n",
    "Visualization of scaling and downsampling results\n",
    "'''\n",
    "# draw3DPoints(source_points, title = \"Before scaling and downsampling\")\n",
    "# draw3DPoints(source_down_points, title = \"After scaling and downsampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30702dfd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Unifying orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb882d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The 3D Morphable model requires a full correspondence between all shapes. In other words, it requires that the points which represent the \"left front tire\" of any car should be matched to the \"left front tire\" of all other cars in the dataset. Thus, to match the points from one model to the corresponding points on another shape, we must have them aligned in same orientation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ee67e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Read data\n",
    "f1 = \"ModelNet40/car/train/car_0001.off\"\n",
    "car_1 = read_pointcloud(f1)\n",
    "#scale to a target size, downsample with specified voxel size\n",
    "car_1, car_1_fpfh = prepare_point_cloud(car_1, target_size=1000, voxel_size=20)\n",
    "car_1 = np.asarray(car_1.points).T\n",
    "\n",
    "f2 = \"ModelNet40/car/train/car_0003.off\"\n",
    "car_2 = read_pointcloud(f2)\n",
    "#scale to a target size, downsample with specified voxel size\n",
    "car_2, car_2_fpfh = prepare_point_cloud(car_2, target_size=1000, voxel_size=20)\n",
    "car_2 = np.asarray(car_2.points).T\n",
    "comparePointClouds(car_1, car_2, title = \"Source: car_1, Target: car_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6fbde",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, we can see that car_0001.off is facing $-y$ direction, car_0003.off is facing $-x$ direction. If we try to find the matching points of \"left front tire\" on car_0003 for car_0001, we would end up getting the \"right front tire\" of car_0003 being matched to car_0001's \"left front tire\". We must move car_0003's center to match the center of car_0001, and rotate car_0003 $90^{\\circ}$ counterclockwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a51ba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### (i) Manually orient cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f3edf0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#move to same center\n",
    "car_1_center = car_1.mean(axis = 1).reshape(3,1)\n",
    "car_1 = car_1 - car_1_center\n",
    "car_2_center = car_2.mean(axis = 1).reshape(3,1)\n",
    "car_2 = car_2 - car_2_center\n",
    "comparePointClouds(car_1, car_2, title = \"Source: car_1, Target: car_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b0e3b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#rotate to same direction\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(car_2.T)\n",
    "R = pcd.get_rotation_matrix_from_xyz((0, 0, np.pi / 2))\n",
    "pcd.rotate(R, center=(0,0,0))\n",
    "car_2 = np.asarray(pcd.points).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12efabdf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comparePointClouds(car_1, car_2, title = \"Source: car_1, Target: car_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da5cf58",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### (ii) Registration algorithms (Ransac + ICP) to orient cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58573bbc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "However, when dealing with large amount of similar 3D models, use registration algorithms is a faster way to orient most cars to same direction. Registration algorithms are usually used to match different captures of same point cloud object. It computes an optimized transformation matrix that maximizes the fitness between the source object and the reference object.\n",
    "\n",
    "According to Open3D's Global Registration Tutorial, a conventional way of matching objects with different orientation is to perform Global Registration algorithms first, and use its resulting transformation matrix as the initial transformation matrix required by Local Registration algorithms for refined alignment.\n",
    "\n",
    "The global registration algorithm we are applying is Ransac. Its parameters are empirical value provided by [Choi, 2015] according to the Open3D documentation. The local refinement algorithm we are using is ICP registration. More details please check [Open3D's Global Registration Tutorial](http://www.open3d.org/docs/release/tutorial/pipelines/global_registration.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f79567",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f1 = \"ModelNet40/car/train/car_0001.off\"\n",
    "car_1 = read_pointcloud(f1)\n",
    "#scale to a target size, downsample with specified voxel size\n",
    "car_1, car_1_fpfh = prepare_point_cloud(car_1, target_size=1000, voxel_size=20)\n",
    "\n",
    "f2 = \"ModelNet40/car/train/car_0003.off\"\n",
    "car_2 = read_pointcloud(f2)\n",
    "#scale to a target size, downsample with specified voxel size\n",
    "car_2, car_2_fpfh = prepare_point_cloud(car_2, target_size=1000, voxel_size=20)\n",
    "\n",
    "comparePointClouds(np.asarray(car_1.points).T, \n",
    "                   np.asarray(car_2.points).T, title = \"Before Registration: Source: car_1, Target: car_2\")\n",
    "\n",
    "ICP_threshold = 15\n",
    "target_size=1000\n",
    "voxel_size=20\n",
    "\n",
    "source_down, source_fpfh = prepare_point_cloud(car_1, target_size, voxel_size)\n",
    "target_down, target_fpfh = prepare_point_cloud(car_2, target_size, voxel_size)\n",
    "\n",
    "GCP_transformation = GCP_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "ICP_transformation = ICP_registration(source_down, target_down, ICP_threshold, GCP_transformation)\n",
    "print(\"Fitness score: {:.2%}\".format(ICP_transformation.fitness))\n",
    "\n",
    "source_temp = copy.deepcopy(source_down)\n",
    "source_temp.transform(ICP_transformation.transformation)\n",
    "\n",
    "comparePointClouds(np.asarray(source_temp.points).T, \n",
    "                   np.asarray(target_down.points).T, title = \"After Registration: Source: car_1, Target: car_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d78192",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that the result is as good as manually orientation. We can also repeat this registration process multiple times to maximize the fitness score between source model and reference model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfab206",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformations = []\n",
    "scores = []\n",
    "for i in range(10):\n",
    "    GCP_transformation = GCP_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "    ICP_transformation = ICP_registration(source_down, target_down, ICP_threshold, GCP_transformation)\n",
    "    transformations.append(ICP_transformation)\n",
    "    scores.append(ICP_transformation.fitness)\n",
    "    \n",
    "max_idx = scores.index(max(scores))\n",
    "Max_Transformation = transformations[max_idx]\n",
    "print(\"Fitness score: {:.2%}\".format(Max_Transformation.fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4e12e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "source_temp = copy.deepcopy(source_down)\n",
    "source_temp.transform(Max_Transformation.transformation)\n",
    "\n",
    "comparePointClouds(np.asarray(source_temp.points).T, \n",
    "                   np.asarray(target_down.points).T, title = \"After Registration: Source: car_1, Target: car_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d603ccb1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Even though this process could fail on some unusual shapes (e.g. align an F1 race car with SUV), it is still efficient when dealing with a large amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3076bc9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3. Preprocess All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc29e09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_and_save(folder = 'ModelNet40/car/',\n",
    "                    ref_name = 'train/car_0002.off', \n",
    "                    save_path = 'data/preprocessed/car/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ed2a1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9c23e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Calculating the average model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34ed720",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we have preprocessed data that have unified sizes and orientations, we can achieve full correspondence within the dataset. \n",
    "First, we can pick a random car as our starting reference shape, and match every point in other cars to the closest point in this reference car. We repeat this process a few times to make sure the average model can represent the entire dataset. The pseudo code is:\n",
    "    \n",
    "    for n repetition:\n",
    "        for every car_i in dataset:\n",
    "            for every point_j in car_reference:\n",
    "                find the index of the closest point in car_i to point_j\n",
    "                save the index\n",
    "\n",
    "            reorder points in car_i by indexes to match the indexes of car_reference\n",
    "        calculate car_average\n",
    "        if the mean squared error between car_average and car_reference is less than threshold:\n",
    "            break loop\n",
    "        update car_reference with car_average\n",
    "        \n",
    "    return the final average shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1549d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#load all preprocessed data\n",
    "f1 = open('data/preprocessed/car/train.txt','rb')\n",
    "train_X = pickle.load(f1)\n",
    "f2 = open('data/preprocessed/car/test.txt','rb')\n",
    "test_X = pickle.load(f2)\n",
    "\n",
    "#select reference model\n",
    "S_reg_index = 1\n",
    "S_reg = train_X[S_reg_index]\n",
    "draw3DPoints(S_reg, 'Reference Car')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8859e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can save all calculated average models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00cda3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "S_mean = train_Mean(train_X, S_reg, 'data/model/car_mean.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b567c22",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#load mean car\n",
    "f1 = open('data/model/car_mean.txt','rb')\n",
    "S_mean_all = pickle.load(f1)\n",
    "for X in S_mean_all:\n",
    "    draw3DPoints(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70338842",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Align all training and testing cars with the average model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5069c47",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we have the average shape, we can achieve full correspondence by aligning each shape in the dataset with the average shape by following the same pseudo code in last small step. This would result to a dataset that each object has same number of points and each point represent the same feature in all cars (e.g. left front tire). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faefc26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#load mean car\n",
    "f1 = open('data/model/car_mean.txt','rb')\n",
    "S_mean_all = pickle.load(f1)\n",
    "#pick average model\n",
    "X_avg = S_mean_all[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90d08b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#align train data\n",
    "train_tilde, train_reorder = reOrder(train_X, S_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4219159",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#save aligned train data\n",
    "aligned_train = open('data/preprocessed/car/train_aligned.txt','wb')\n",
    "pickle.dump(train_reorder, aligned_train)\n",
    "#load all aligned cars, if fail save again\n",
    "f1 = open('data/preprocessed/car/train_aligned.txt','rb')\n",
    "X_train = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8810d53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#align test data\n",
    "test_tilde, test_reorder = reOrder(test_X, S_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f934bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#save aligned train data, if fail save again\n",
    "aligned_test = open('data/preprocessed/car/test_aligned.txt','wb')\n",
    "pickle.dump(test_reorder, aligned_test)\n",
    "f2 = open('data/preprocessed/car/test_aligned.txt','rb')\n",
    "X_test = pickle.load(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883251d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Calculating eigenvectors with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d32697",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Our data is currently in shape (3, n). In order to calculate the eigenvectors from the entire datset, we can flatten our data and represent it with a shape-vector $S = (x_{1}, y_{1}, z_{1}, x_{2}, ..., x_{n}, y_{n}, z_{n}) \\in \\mathbb{R}^{3n}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f5f4ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#load all aligned cars\n",
    "f1 = open('data/preprocessed/car/train_aligned.txt','rb')\n",
    "X_train = pickle.load(f1)\n",
    "f2 = open('data/preprocessed/car/test_aligned.txt','rb')\n",
    "X_test = pickle.load(f2)\n",
    "\n",
    "#load average model\n",
    "average_models = open('data/model/car_mean.txt','rb')\n",
    "mean_Xs = pickle.load(average_models)\n",
    "X_avg = mean_Xs[-1]\n",
    "X_avg_flat = X_avg.flatten('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d7fb6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# flatten data from (3, n) to (3n, 1)\n",
    "X_train_flat = pointcloud_to_flat(X_train)\n",
    "X_test_flat = pointcloud_to_flat(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f17b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### PCA get eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3b5b3e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Singular value decomposition (SVD) can factorize a matrix into three seperate matrices  $U$, $D$, and $V$. Here, our input matrix is in shape $(m, 3n)$ where $m$ is the number of objects in the dataset and $n$ is the number of 3d coordinate in each object. SVD would decompose this matrix of data into $U$ that its column vectors spans $\\mathbb{R}^{m}$, $D$ that is a diagonal matrix of the square root of nonzero eigenvalues of our input matrix, and $V$ that its column vectors spans $\\mathbb{R}^{3n}$. Since we only have $m$ objects in our dataset, the nubmer of nonzero eigenvalues generated by SVD should also be $m$. Which means that only the first 193 column vectors of $V$ can represent our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ad6e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "U, D, V = np.linalg.svd(X_train_flat - X_avg_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ae770",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.clf\n",
    "plt.plot(D, '.-')\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa90072",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Try to fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b91465",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We know that a new model can be described by this linear function:\n",
    "$$\n",
    "S_{model} = \\overline{S} + \\sum_{i=1}^{m - 1}\\alpha_{i}s_{i}\n",
    "$$\n",
    "Thus, \n",
    "$$\n",
    "S_{model} - \\overline{S} = \\sum_{i=1}^{m - 1}\\alpha_{i}s_{i} = \\mathbf{\\alpha}\\mathbf{s}\n",
    "$$\n",
    "where $\\mathbf{\\alpha}$ represent the weights of eigenvectors in columns of $\\mathbf{s}$.\n",
    "Since eigenvectors are orthogonal with each other (i.e. $\\langle s_{i},s_{j}\\rangle_{j \\neq i} = 0$, $\\langle s_{i},s_{i}\\rangle = 1$), we can compute the weights $\\mathbf{\\alpha}$ by multiplying $S_{model} - \\overline{S}$ with $\\mathbf{s}$:\n",
    "\n",
    "$$\n",
    "(S_{model} - \\overline{S}) \\mathbf{s} = \\sum_{i=1}^{m - 1}\\sum_{j=1}^{m - 1}\\alpha_{i}\\langle s_{i},s_{j}\\rangle = \\mathbf{\\alpha}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b8c544",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#fit model with test shape\n",
    "carMM = MorphableModel(X_avg, V, len(D))\n",
    "\n",
    "i=3\n",
    "fitted_model = carMM.fit(X_test_flat[i])\n",
    "fitted_model_3D = single_flat_to_pointcloud(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e21acb",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Mean Squared Error between original model and average model: %.4f\"%(((X_test_flat[i] - X_avg_flat)**2).mean()))\n",
    "print(\"Mean Squared Error between original model and fitted model: %.4f\"%(((X_test_flat[i] - fitted_model)**2).mean()))\n",
    "draw3DPoints(X_test[i], 'Original test shape')\n",
    "draw3DPoints(fitted_model_3D, 'Fitted test shape')\n",
    "draw3DPoints(X_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa9ecc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can observe from the above plots that the linear function can already capture the shape of our test car. The fitted shape is a vague silhouette since this is a global shape morphable model and we only have 191 data. The details in the fitted shape can be improved if we apply local shape morphable model which requires a segmentation on the shape before computing the linear generator function for morphable model on different parts such as windshield, tires, or seats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e904f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3: Evaluating Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83749c7a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot Mean Squared Error vs. Number of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71aced",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to define an optimized number of features between $0$ and $m$(number of objects in training set), we can plot Mean Squared Error between a test shape and the shape fitted onto it with different number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7fac9f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_MSE_n_feature(X_test_flat, V, X_avg, len(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124429d3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can observe from the plot that the first 50 features reduced most of the errors. It means that most of the variations in the shapes can be explained by the first 50 features. Thus, we can examine these features and check what do they actually control in creating a new car shape from the morphable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d9e10",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## \n",
    "weights_all = []\n",
    "for i_fet in range(len(D)):\n",
    "    features = V[:,i_fet]\n",
    "    w = (X_test_flat - X_avg.flatten('F'))@features\n",
    "    weights_all.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994171b",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#we only examine first 50 eigenvectors\n",
    "draw3DpointsSlider(V, 0, X_avg, weights_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dbe9c4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Now is time to create your own car with morphable model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605bc317",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_car = create_new_car(V, X_avg, weights_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f72a01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a7cb3f514f84ac8fda924ee5932a7d3539aa40abb3ffdb8f9081782add7e3b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
